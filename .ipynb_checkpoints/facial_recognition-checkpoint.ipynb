{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Recognition Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A csv file with facial expression data is provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "data_path = 'data.csv'\n",
    "image_size=(48,48)\n",
    "\n",
    "def load_data(data_path):\n",
    "        data = pd.read_csv(data_path)\n",
    "        pixels = data['pixels'].tolist()\n",
    "        width, height = 48, 48\n",
    "        faces = []\n",
    "        for pixel_sequence in pixels:\n",
    "            face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "            face = np.asarray(face).reshape(width, height)\n",
    "            face = cv2.resize(face.astype('uint8'),image_size)\n",
    "            faces.append(face.astype('float32'))\n",
    "        faces = np.asarray(faces)\n",
    "        faces = np.expand_dims(faces, -1)\n",
    "\n",
    "        emotions = pd.get_dummies(data['emotion']).values\n",
    "        return faces, emotions\n",
    "    \n",
    "faces, emotions = load_data(data_path); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A sample face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Labels [1 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x943a128>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ind = 0\n",
    "f = faces[ind, :,:,0]\n",
    "print('Emotion Labels', emotions[ind,:])\n",
    "plt.imshow(f, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.regularizers import l2\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import keras\n",
    "import imageio\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23744, 48, 48, 1)\n",
      "x_train shape: (21369, 48, 48, 1) y_train shape: (21369, 6)\n",
      "x_val shape: (2375, 48, 48, 1) y_val shape: (2375, 6)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(faces, emotions, test_size=0.1, random_state=2020)\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_val = x_val.astype('float32') / 255\n",
    "print(faces.shape)\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"x_val shape:\", x_val.shape, \"y_val shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "augmented_train = []\n",
    "augmented_train_label = []\n",
    "for img, label in zip(x_train, y_train):\n",
    "    image_array = image.img_to_array(img)\n",
    "    augmented_train.append(image_array)\n",
    "    augmented_train_label.append(label)\n",
    "    \n",
    "    flip_hr=iaa.Fliplr(p=1.0)\n",
    "    flip_hr_image= flip_hr.augment_image(img)\n",
    "    image_array = image.img_to_array(flip_hr_image)\n",
    "    augmented_train.append(image_array)\n",
    "    augmented_train_label.append(label)\n",
    "    \n",
    "    \n",
    "    flip_vr=iaa.Flipud(p=1.0)\n",
    "    flip_vr_image= flip_vr.augment_image(f)\n",
    "    image_array = image.img_to_array(flip_vr_image)\n",
    "    augmented_train.append(image_array)\n",
    "    augmented_train_label.append(label)\n",
    "    \n",
    "    flip_twice= flip_vr.augment_image(flip_hr_image)\n",
    "    #ia.imshow(flip_twice)\n",
    "    image_array = image.img_to_array(flip_twice)\n",
    "    augmented_train.append(image_array)\n",
    "    augmented_train_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the list into numpy array\n",
    "train_images = np.asarray(augmented_train,dtype='float32')\n",
    "train_label = np.asarray(augmented_train_label,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (85476, 48, 48, 1) y_train shape: (85476, 6)\n",
      "x_val shape: (2375, 48, 48, 1) y_val shape: (2375, 6)\n"
     ]
    }
   ],
   "source": [
    "x_train = train_images\n",
    "y_train = train_label\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"x_val shape:\", x_val.shape, \"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicating the grayscale to RGB (3 Channels) for ResNet and Other state of the art architecture\n",
    "# Not used\n",
    "# rgb_batch = np.repeat(faces[...], 3, -1)    \n",
    "# print(rgb_batch.shape)\n",
    "\n",
    "# x_train, x_val, y_train, y_val = train_test_split(rgb_batch, emotions, test_size=0.2, random_state=2020)\n",
    "# x_train = x_train.astype('float32') / 255\n",
    "# x_val = x_val.astype('float32') / 255\n",
    "# print(faces.shape)\n",
    "# print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "# print(\"x_val shape:\", x_val.shape, \"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Current second best but short\n",
    "# model = tf.keras.Sequential([\n",
    "#     layers.Conv2D(64, (5, 5), input_shape=[48, 48, 1]),\n",
    "#     layers.MaxPool2D((3,3), strides=2),\n",
    "#     layers.Conv2D(64, (5, 5)),\n",
    "#     layers.MaxPool2D((3,3), strides=2),\n",
    "#     layers.Conv2D(128, (4, 4)),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(3072, activation='relu'),\n",
    "#     layers.Dropout(0.4),\n",
    "#     layers.Dense(6, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Current best model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1), data_format='channels_last', kernel_regularizer=l2(0.01)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Flatten(),\n",
    "\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Dense(6, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet trial\n",
    "# Not used\n",
    "# base_model = tf.keras.applications.ResNet50(input_shape=(48, 48, 3), include_top=False)\n",
    "# model = tf.keras.Sequential([\n",
    "#     base_model,\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(6, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 46, 46, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 23, 23, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 23, 23, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 23, 23, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 23, 23, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 5, 5, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 6,069,830\n",
      "Trainable params: 6,066,118\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the early stopper and checkpointer\n",
    "\n",
    "MODELPATH = r\"C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\"\n",
    "tensorboard = TensorBoard(log_dir='./logs')\n",
    "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(MODELPATH, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 85476 samples, validate on 2375 samples\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.6977 - acc: 0.2965\n",
      "Epoch 00001: val_loss improved from inf to 1.64744, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 111s 1ms/sample - loss: 1.6977 - acc: 0.2965 - val_loss: 1.6474 - val_acc: 0.2994\n",
      "Epoch 2/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.6432 - acc: 0.3039\n",
      "Epoch 00002: val_loss improved from 1.64744 to 1.62359, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 109s 1ms/sample - loss: 1.6431 - acc: 0.3040 - val_loss: 1.6236 - val_acc: 0.3048\n",
      "Epoch 3/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.6257 - acc: 0.3040\n",
      "Epoch 00003: val_loss did not improve from 1.62359\n",
      "85476/85476 [==============================] - 109s 1ms/sample - loss: 1.6257 - acc: 0.3041 - val_loss: 1.7163 - val_acc: 0.2872\n",
      "Epoch 4/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.6130 - acc: 0.3133\n",
      "Epoch 00004: val_loss improved from 1.62359 to 1.55742, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.6131 - acc: 0.3133 - val_loss: 1.5574 - val_acc: 0.3427\n",
      "Epoch 5/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.5643 - acc: 0.3409\n",
      "Epoch 00005: val_loss improved from 1.55742 to 1.41593, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.5643 - acc: 0.3410 - val_loss: 1.4159 - val_acc: 0.4135\n",
      "Epoch 6/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.4780 - acc: 0.3880\n",
      "Epoch 00006: val_loss improved from 1.41593 to 1.28183, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.4779 - acc: 0.3881 - val_loss: 1.2818 - val_acc: 0.4716\n",
      "Epoch 7/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.4016 - acc: 0.4217\n",
      "Epoch 00007: val_loss improved from 1.28183 to 1.25596, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.4014 - acc: 0.4218 - val_loss: 1.2560 - val_acc: 0.4998\n",
      "Epoch 8/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.3588 - acc: 0.4405\n",
      "Epoch 00008: val_loss did not improve from 1.25596\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.3589 - acc: 0.4405 - val_loss: 1.2630 - val_acc: 0.4733\n",
      "Epoch 9/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.3181 - acc: 0.4554\n",
      "Epoch 00009: val_loss improved from 1.25596 to 1.13141, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.3181 - acc: 0.4554 - val_loss: 1.1314 - val_acc: 0.5347\n",
      "Epoch 10/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.2910 - acc: 0.4667\n",
      "Epoch 00010: val_loss did not improve from 1.13141\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.2910 - acc: 0.4667 - val_loss: 1.1368 - val_acc: 0.5440\n",
      "Epoch 11/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.2699 - acc: 0.4740\n",
      "Epoch 00011: val_loss improved from 1.13141 to 1.10456, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.2700 - acc: 0.4740 - val_loss: 1.1046 - val_acc: 0.5364\n",
      "Epoch 12/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.2467 - acc: 0.4856\n",
      "Epoch 00012: val_loss improved from 1.10456 to 1.07736, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.2467 - acc: 0.4856 - val_loss: 1.0774 - val_acc: 0.5722\n",
      "Epoch 13/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.2259 - acc: 0.4958\n",
      "Epoch 00013: val_loss improved from 1.07736 to 1.07319, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 112s 1ms/sample - loss: 1.2259 - acc: 0.4958 - val_loss: 1.0732 - val_acc: 0.5726\n",
      "Epoch 14/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.2048 - acc: 0.5104\n",
      "Epoch 00014: val_loss improved from 1.07319 to 1.04084, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 112s 1ms/sample - loss: 1.2048 - acc: 0.5104 - val_loss: 1.0408 - val_acc: 0.5912\n",
      "Epoch 15/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.1834 - acc: 0.5216\n",
      "Epoch 00015: val_loss improved from 1.04084 to 1.00695, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 112s 1ms/sample - loss: 1.1834 - acc: 0.5216 - val_loss: 1.0069 - val_acc: 0.6105\n",
      "Epoch 16/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.1692 - acc: 0.5312\n",
      "Epoch 00016: val_loss did not improve from 1.00695\n",
      "85476/85476 [==============================] - 111s 1ms/sample - loss: 1.1691 - acc: 0.5312 - val_loss: 1.0744 - val_acc: 0.5869\n",
      "Epoch 17/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.1499 - acc: 0.5377\n",
      "Epoch 00017: val_loss improved from 1.00695 to 0.98412, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 111s 1ms/sample - loss: 1.1499 - acc: 0.5377 - val_loss: 0.9841 - val_acc: 0.6333\n",
      "Epoch 18/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.1315 - acc: 0.5472\n",
      "Epoch 00018: val_loss did not improve from 0.98412\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.1315 - acc: 0.5472 - val_loss: 0.9845 - val_acc: 0.6337\n",
      "Epoch 19/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.1229 - acc: 0.5498\n",
      "Epoch 00019: val_loss improved from 0.98412 to 0.96985, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.1230 - acc: 0.5497 - val_loss: 0.9698 - val_acc: 0.6337\n",
      "Epoch 20/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.1071 - acc: 0.5580\n",
      "Epoch 00020: val_loss did not improve from 0.96985\n",
      "85476/85476 [==============================] - 109s 1ms/sample - loss: 1.1072 - acc: 0.5580 - val_loss: 0.9781 - val_acc: 0.6429\n",
      "Epoch 21/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.0914 - acc: 0.5635\n",
      "Epoch 00021: val_loss improved from 0.96985 to 0.94165, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.0914 - acc: 0.5635 - val_loss: 0.9416 - val_acc: 0.6552\n",
      "Epoch 22/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.0812 - acc: 0.5688\n",
      "Epoch 00022: val_loss improved from 0.94165 to 0.93389, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 109s 1ms/sample - loss: 1.0812 - acc: 0.5688 - val_loss: 0.9339 - val_acc: 0.6488\n",
      "Epoch 23/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.0687 - acc: 0.5746\n",
      "Epoch 00023: val_loss did not improve from 0.93389\n",
      "85476/85476 [==============================] - 109s 1ms/sample - loss: 1.0687 - acc: 0.5746 - val_loss: 0.9581 - val_acc: 0.6312\n",
      "Epoch 24/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.0572 - acc: 0.5777\n",
      "Epoch 00024: val_loss did not improve from 0.93389\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.0572 - acc: 0.5777 - val_loss: 0.9606 - val_acc: 0.6518\n",
      "Epoch 25/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.0474 - acc: 0.5816\n",
      "Epoch 00025: val_loss improved from 0.93389 to 0.91372, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.0473 - acc: 0.5816 - val_loss: 0.9137 - val_acc: 0.6493\n",
      "Epoch 26/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.0340 - acc: 0.5866\n",
      "Epoch 00026: val_loss did not improve from 0.91372\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.0340 - acc: 0.5866 - val_loss: 0.9188 - val_acc: 0.6539\n",
      "Epoch 27/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.0276 - acc: 0.5885\n",
      "Epoch 00027: val_loss did not improve from 0.91372\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.0276 - acc: 0.5885 - val_loss: 0.9400 - val_acc: 0.6493\n",
      "Epoch 28/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 1.0149 - acc: 0.5928\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.91372\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 1.0149 - acc: 0.5928 - val_loss: 0.9231 - val_acc: 0.6653\n",
      "Epoch 29/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 0.9990 - acc: 0.6006\n",
      "Epoch 00029: val_loss did not improve from 0.91372\n",
      "85476/85476 [==============================] - 110s 1ms/sample - loss: 0.9989 - acc: 0.6006 - val_loss: 0.9221 - val_acc: 0.6611\n",
      "Epoch 30/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 0.9890 - acc: 0.6043\n",
      "Epoch 00030: val_loss improved from 0.91372 to 0.91018, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 111s 1ms/sample - loss: 0.9891 - acc: 0.6043 - val_loss: 0.9102 - val_acc: 0.6754\n",
      "Epoch 31/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 0.9782 - acc: 0.6089\n",
      "Epoch 00031: val_loss improved from 0.91018 to 0.89560, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 111s 1ms/sample - loss: 0.9783 - acc: 0.6088 - val_loss: 0.8956 - val_acc: 0.6779\n",
      "Epoch 32/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 0.9694 - acc: 0.6131\n",
      "Epoch 00032: val_loss did not improve from 0.89560\n",
      "85476/85476 [==============================] - 111s 1ms/sample - loss: 0.9693 - acc: 0.6131 - val_loss: 0.9073 - val_acc: 0.6661\n",
      "Epoch 33/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 0.9596 - acc: 0.6159\n",
      "Epoch 00033: val_loss did not improve from 0.89560\n",
      "85476/85476 [==============================] - 112s 1ms/sample - loss: 0.9596 - acc: 0.6159 - val_loss: 0.8957 - val_acc: 0.6800\n",
      "Epoch 34/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 0.9540 - acc: 0.6192\n",
      "Epoch 00034: val_loss improved from 0.89560 to 0.87637, saving model to C:\\Users\\Rico\\Documents\\Deep learning\\assignment2_forClass\\model_aug.h5\n",
      "85476/85476 [==============================] - 111s 1ms/sample - loss: 0.9540 - acc: 0.6192 - val_loss: 0.8764 - val_acc: 0.6754\n",
      "Epoch 35/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 0.9389 - acc: 0.6247\n",
      "Epoch 00035: val_loss did not improve from 0.87637\n",
      "85476/85476 [==============================] - 111s 1ms/sample - loss: 0.9389 - acc: 0.6247 - val_loss: 0.9154 - val_acc: 0.6745\n",
      "Epoch 36/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 0.9413 - acc: 0.6234\n",
      "Epoch 00036: val_loss did not improve from 0.87637\n",
      "85476/85476 [==============================] - 111s 1ms/sample - loss: 0.9413 - acc: 0.6234 - val_loss: 0.9009 - val_acc: 0.6762\n",
      "Epoch 37/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 0.9287 - acc: 0.6291\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.87637\n",
      "85476/85476 [==============================] - 114s 1ms/sample - loss: 0.9286 - acc: 0.6291 - val_loss: 0.8997 - val_acc: 0.6787\n",
      "Epoch 38/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 0.9135 - acc: 0.6339\n",
      "Epoch 00038: val_loss did not improve from 0.87637\n",
      "85476/85476 [==============================] - 117s 1ms/sample - loss: 0.9137 - acc: 0.6339 - val_loss: 0.9128 - val_acc: 0.6796\n",
      "Epoch 39/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 0.9070 - acc: 0.6377\n",
      "Epoch 00039: val_loss did not improve from 0.87637\n",
      "85476/85476 [==============================] - 112s 1ms/sample - loss: 0.9070 - acc: 0.6377 - val_loss: 0.8812 - val_acc: 0.6817\n",
      "Epoch 40/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 0.8982 - acc: 0.6423\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.87637\n",
      "85476/85476 [==============================] - 111s 1ms/sample - loss: 0.8982 - acc: 0.6423 - val_loss: 0.9008 - val_acc: 0.6842\n",
      "Epoch 41/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 0.8839 - acc: 0.6460\n",
      "Epoch 00041: val_loss did not improve from 0.87637\n",
      "85476/85476 [==============================] - 111s 1ms/sample - loss: 0.8839 - acc: 0.6460 - val_loss: 0.9005 - val_acc: 0.6851\n",
      "Epoch 42/300\n",
      "85440/85476 [============================>.] - ETA: 0s - loss: 0.8757 - acc: 0.6517\n",
      "Epoch 00042: val_loss did not improve from 0.87637\n",
      "85476/85476 [==============================] - 111s 1ms/sample - loss: 0.8756 - acc: 0.6517 - val_loss: 0.9003 - val_acc: 0.6834\n",
      "Epoch 00042: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Running the model\n",
    "history = model.fit(x_train, y_train, batch_size=64, verbose=1, validation_data = (x_val, y_val), epochs=300, callbacks=[lr_reducer, tensorboard, early_stopper, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "model.save(\"model_final_aug.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start from here if wanted to check the result only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary function to check the result\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23744, 48, 48, 1)\n",
      "x_train shape: (21369, 48, 48, 1) y_train shape: (21369, 6)\n",
      "x_val shape: (2375, 48, 48, 1) y_val shape: (2375, 6)\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "data_path = 'dataForClass.csv'\n",
    "image_size=(48,48)\n",
    "\n",
    "def load_data(data_path):\n",
    "        data = pd.read_csv(data_path)\n",
    "        pixels = data['pixels'].tolist()\n",
    "        width, height = 48, 48\n",
    "        faces = []\n",
    "        for pixel_sequence in pixels:\n",
    "            face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "            face = np.asarray(face).reshape(width, height)\n",
    "            face = cv2.resize(face.astype('uint8'),image_size)\n",
    "            faces.append(face.astype('float32'))\n",
    "        faces = np.asarray(faces)\n",
    "        faces = np.expand_dims(faces, -1)\n",
    "\n",
    "        emotions = pd.get_dummies(data['emotion']).values\n",
    "        return faces, emotions\n",
    "    \n",
    "faces, emotions = load_data(data_path); \n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(faces, emotions, test_size=0.1, random_state=2020)\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_val = x_val.astype('float32') / 255\n",
    "print(faces.shape)\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"x_val shape:\", x_val.shape, \"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Loading the best model based on validation loss\n",
    "model = tf.keras.models.load_model('model_aug.h5')\n",
    "# Load 'model.h5' if wanted to check the model without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the final model\n",
    "# Has a slightly higher accuracy but higher loss too\n",
    "model = tf.keras.models.load_model('model_final_aug.h5')\n",
    "# Load 'model_final.h5' if wanted to check the model without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8763663872417651\n",
      "Test accuracy: 0.6753684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.54      0.59       399\n",
      "           2       0.75      0.14      0.23        44\n",
      "           3       0.48      0.42      0.45       421\n",
      "           4       0.87      0.87      0.87       711\n",
      "           5       0.53      0.76      0.62       464\n",
      "           6       0.79      0.70      0.74       336\n",
      "\n",
      "    accuracy                           0.68      2375\n",
      "   macro avg       0.68      0.57      0.58      2375\n",
      "weighted avg       0.69      0.68      0.67      2375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out some evaluation metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Print the loss and accuracy of the test data\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "label_names = ['1','2','3','4','5','6']\n",
    "# Print the confusion matrix\n",
    "test_predict = model.predict_classes(x_val)\n",
    "predict = model.predict(x_val)\n",
    "print(classification_report(y_val.argmax(axis=1), predict.argmax(axis=1), target_names = label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial expression data is modified from https://www.kaggle.com/c/3364\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
